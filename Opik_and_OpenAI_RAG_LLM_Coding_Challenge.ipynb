{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4lyGVV413Ry"
      },
      "source": [
        "# Example RAG with Opik Tracing and Evals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndkY7MxbsUYr"
      },
      "source": [
        "This simple example will get you started with using Opik, Weaviate, and the OpenAI API to build a RAG system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQl7CHhX3XBF"
      },
      "source": [
        "# Set up your Environment\n",
        "\n",
        "[Comet](https://www.comet.com/) provides a hosted version of the Opik platform, simply [create a free account](https://www.comet.com/site/products/opik/) and grab you API Key from the UI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQdYMW091iz0"
      },
      "source": [
        "First, we need pip install the opik and openai libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "063DSqmmqKQM",
        "outputId": "e52990b3-c55f-43b1-f861-e31af0811989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U opik openai --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D238f3uZ1mPG"
      },
      "source": [
        "Now, we'll configure Opik and OpenAI with our respective API keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7uYVtVMqNhs",
        "outputId": "dd935aef-971a-4aa7-b0f9-31e5a6110385"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OPIK: Existing Opik clients will not use updated values for \"url\", \"api_key\", \"workspace\".\n",
            "OPIK: Opik is already configured. You can check the settings by viewing the config file at C:\\Users\\nicet\\.opik.config\n"
          ]
        }
      ],
      "source": [
        "import opik\n",
        "\n",
        "opik.configure(use_local=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwlbJ_F4qPdd",
        "outputId": "ba098437-563d-4af3-d1ba-7ec3e901f866"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuy9Dmg01s9H"
      },
      "source": [
        "Traces will now be automatically logged to the Opik UI where you can inspect the inputs, outputs, and configure evaluation metrics. After you run this cell, follow the link to the Comet UI to see you traces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCSQN2_x0-sQ"
      },
      "source": [
        "# Set up Weaviate Client\n",
        "\n",
        "Weaviate is a vector database which supports billion scale vector search with sub 50ms query times. We'll use Weaviate to query for books in this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGW4xKQDrTou",
        "outputId": "737c46ee-1eb9-458b-ce19-384623eaefe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U weaviate-client --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_tbFISQ0-gr",
        "outputId": "6a10f2dd-7f6d-4e16-eff4-5d455f2bdd62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import weaviate\n",
        "from weaviate.classes.init import Auth\n",
        "from weaviate.classes.init import AdditionalConfig, Timeout\n",
        "\n",
        "\n",
        "WEAVIATE_CLUSTER_URL = os.getenv('WEAVIATE_CLUSTER_URL') or 'https://zxzyqcyksbw7ozpm5yowa.c0.us-west2.gcp.weaviate.cloud'\n",
        "WEAVIATE_API_KEY = os.getenv('WEAVIATE_API_KEY') or 'n6mdfI32xrXF3DH76i8Pwc2IajzLZop2igb6' # This is a read key\n",
        "\n",
        "weaviate_client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=WEAVIATE_CLUSTER_URL,\n",
        "    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n",
        "    headers={\"X-OpenAI-Api-Key\": os.environ[\"OPENAI_API_KEY\"]},\n",
        ")\n",
        "\n",
        "print(weaviate_client.is_connected())\n",
        "\n",
        "book_collection = weaviate_client.collections.get(name=\"Book\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkdxVeQcOvQ"
      },
      "source": [
        "# Write a RAG app with OpenAI, Weaviate and Opik Traces\n",
        "\n",
        "Next, we will build a very simple LLM reasoning application and log the trace data to Opik where we can apply additional evaluation metrics and debug the LLM response.\n",
        "\n",
        "We will use Opik to collect traces to inspect the inputs and outputs of the reasoning tasks, and to create evaluation metrics for hallicinations and other common or custom issues you want to detect.\n",
        "\n",
        "Opik integrates with OpenAI to provide a simple way to log traces for all OpenAI LLM calls. This works for all OpenAI models, including if you are using the streaming API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ciD73aK2qDXc"
      },
      "outputs": [],
      "source": [
        "from opik.integrations.openai import track_openai\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"OPIK_PROJECT_NAME\"] = \"rag-project\" #name your project. This will appear as the project name in the Opik UI\n",
        "\n",
        "\n",
        "client = OpenAI()\n",
        "client = track_openai(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYUzfsnvY7JG"
      },
      "source": [
        "We are using the @opik.track decorator and the OpenAI logging integration to automatically log our traces and spans. Learn more here https://www.comet.com/docs/opik/tracing/log_traces#using-an-integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hbxVyTwdYC4R"
      },
      "outputs": [],
      "source": [
        "@opik.track\n",
        "def retrieve_context(user_query):\n",
        "    # Semantic Search\n",
        "    response = book_collection.query.near_text(\n",
        "        query=user_query,\n",
        "        limit=3\n",
        "    )\n",
        "\n",
        "    recommended_books = []\n",
        "    for book in response.objects:\n",
        "        recommended_books.append(book.properties['title'])\n",
        "    return recommended_books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "T4jYELuJ1Zjo"
      },
      "outputs": [],
      "source": [
        "@opik.track\n",
        "def generate_response(user_query, recommended_books):\n",
        "  prompt = f\"\"\"\n",
        "  You're a helpful assistant, reply to a chatbot message for someone inquiring for\n",
        "  book recommendations. The user query was {user_query}\n",
        "\n",
        "\n",
        "  These were the book that were extracted from the vector\n",
        "  search:\n",
        "\n",
        "  {recommended_books}\n",
        "  \"\"\"\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"o3-mini\",\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt\n",
        "          }\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-LhqAN_y2xS-"
      },
      "outputs": [],
      "source": [
        "@opik.track(name=\"rag-example\")\n",
        "def llm_chain(user_query):\n",
        "    context = retrieve_context(user_query)\n",
        "    response = generate_response(user_query, context)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fozL4CdW6lO",
        "outputId": "2e527653-a134-4d3b-9593-767e7bdf779e"
      },
      "outputs": [
        {
          "ename": "WeaviateQueryError",
          "evalue": "Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"explorer: get class: vectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: connection to: OpenAI API failed with status: 429 request-id: req_7aab3df7c2cb22a7a851889a26e75bdd error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"explorer: get class: vectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: connection to: OpenAI API failed with status: 429 request-id: req_7aab3df7c2cb22a7a851889a26e75bdd error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", grpc_status:2, created_time:\"2025-03-06T02:41:14.0203446+00:00\"}\"\n>.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAioRpcError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\weaviate\\collections\\grpc\\query.py:478\u001b[39m, in \u001b[36m_QueryGRPC.__call\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.grpc_stub \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m res = \u001b[38;5;28;01mawait\u001b[39;00m _Retry(\u001b[32m4\u001b[39m).with_exponential_backoff(\n\u001b[32m    479\u001b[39m     \u001b[32m0\u001b[39m,\n\u001b[32m    480\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSearching in collection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest.collection\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    481\u001b[39m     \u001b[38;5;28mself\u001b[39m._connection.grpc_stub.Search,\n\u001b[32m    482\u001b[39m     request,\n\u001b[32m    483\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._connection.grpc_headers(),\n\u001b[32m    484\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m._connection.timeout_config.query,\n\u001b[32m    485\u001b[39m )\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(search_get_pb2.SearchReply, res)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\weaviate\\collections\\grpc\\retry.py:31\u001b[39m, in \u001b[36m_Retry.with_exponential_backoff\u001b[39m\u001b[34m(self, count, error, f, *args, **kwargs)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m e.code() != StatusCode.UNAVAILABLE:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     32\u001b[39m logger.info(\n\u001b[32m     33\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m received exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Retrying with exponential backoff in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[32m2\u001b[39m**count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     34\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\weaviate\\collections\\grpc\\retry.py:28\u001b[39m, in \u001b[36m_Retry.with_exponential_backoff\u001b[39m\u001b[34m(self, count, error, f, *args, **kwargs)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m f(*args, **kwargs)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m AioRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\grpc\\aio\\_call.py:327\u001b[39m, in \u001b[36m_UnaryResponseMixin.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m _create_rpc_error(\n\u001b[32m    328\u001b[39m             \u001b[38;5;28mself\u001b[39m._cython_call._initial_metadata,\n\u001b[32m    329\u001b[39m             \u001b[38;5;28mself\u001b[39m._cython_call._status,\n\u001b[32m    330\u001b[39m         )\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mAioRpcError\u001b[39m: <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"explorer: get class: vectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: connection to: OpenAI API failed with status: 429 request-id: req_7aab3df7c2cb22a7a851889a26e75bdd error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"explorer: get class: vectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: connection to: OpenAI API failed with status: 429 request-id: req_7aab3df7c2cb22a7a851889a26e75bdd error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", grpc_status:2, created_time:\"2025-03-06T02:41:14.0203446+00:00\"}\"\n>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mWeaviateQueryError\u001b[39m                        Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Use the LLM chain\u001b[39;00m\n\u001b[32m      2\u001b[39m user_query = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWhat types of books are you looking for? \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43mllm_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\opik\\decorator\\base_track_decorator.py:299\u001b[39m, in \u001b[36mBaseTrackDecorator._tracked_sync.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m     LOGGER.debug(\n\u001b[32m    292\u001b[39m         logging_messages.EXCEPTION_RAISED_FROM_TRACKED_FUNCTION,\n\u001b[32m    293\u001b[39m         func.\u001b[34m__name__\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m         exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    297\u001b[39m     )\n\u001b[32m    298\u001b[39m     error_info = error_info_collector.collect(exception)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    301\u001b[39m     stream_or_stream_manager = \u001b[38;5;28mself\u001b[39m._streams_handler(\n\u001b[32m    302\u001b[39m         result,\n\u001b[32m    303\u001b[39m         track_options.capture_output,\n\u001b[32m    304\u001b[39m         track_options.generations_aggregator,\n\u001b[32m    305\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\opik\\decorator\\base_track_decorator.py:289\u001b[39m, in \u001b[36mBaseTrackDecorator._tracked_sync.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    287\u001b[39m error_info: Optional[ErrorInfoDict] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m    291\u001b[39m     LOGGER.debug(\n\u001b[32m    292\u001b[39m         logging_messages.EXCEPTION_RAISED_FROM_TRACKED_FUNCTION,\n\u001b[32m    293\u001b[39m         func.\u001b[34m__name__\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m         exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    297\u001b[39m     )\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mllm_chain\u001b[39m\u001b[34m(user_query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;129m@opik\u001b[39m.track(name=\u001b[33m\"\u001b[39m\u001b[33mrag-example\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm_chain\u001b[39m(user_query):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     context = \u001b[43mretrieve_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     response = generate_response(user_query, context)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\opik\\decorator\\base_track_decorator.py:299\u001b[39m, in \u001b[36mBaseTrackDecorator._tracked_sync.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m     LOGGER.debug(\n\u001b[32m    292\u001b[39m         logging_messages.EXCEPTION_RAISED_FROM_TRACKED_FUNCTION,\n\u001b[32m    293\u001b[39m         func.\u001b[34m__name__\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m         exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    297\u001b[39m     )\n\u001b[32m    298\u001b[39m     error_info = error_info_collector.collect(exception)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    301\u001b[39m     stream_or_stream_manager = \u001b[38;5;28mself\u001b[39m._streams_handler(\n\u001b[32m    302\u001b[39m         result,\n\u001b[32m    303\u001b[39m         track_options.capture_output,\n\u001b[32m    304\u001b[39m         track_options.generations_aggregator,\n\u001b[32m    305\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\opik\\decorator\\base_track_decorator.py:289\u001b[39m, in \u001b[36mBaseTrackDecorator._tracked_sync.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    287\u001b[39m error_info: Optional[ErrorInfoDict] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m    291\u001b[39m     LOGGER.debug(\n\u001b[32m    292\u001b[39m         logging_messages.EXCEPTION_RAISED_FROM_TRACKED_FUNCTION,\n\u001b[32m    293\u001b[39m         func.\u001b[34m__name__\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m         exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    297\u001b[39m     )\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mretrieve_context\u001b[39m\u001b[34m(user_query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;129m@opik\u001b[39m.track\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve_context\u001b[39m(user_query):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Semantic Search\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     response = \u001b[43mbook_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnear_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     recommended_books = []\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m book \u001b[38;5;129;01min\u001b[39;00m response.objects:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\weaviate\\syncify.py:23\u001b[39m, in \u001b[36mconvert.<locals>.sync_method\u001b[39m\u001b[34m(self, __new_name, *args, **kwargs)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(method)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msync_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, __new_name=new_name, **kwargs):\n\u001b[32m     22\u001b[39m     async_func = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, __new_name)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_EventLoopSingleton\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43masync_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\weaviate\\event_loop.py:42\u001b[39m, in \u001b[36m_EventLoop.run_until_complete\u001b[39m\u001b[34m(self, f, *args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateClosedClientError()\n\u001b[32m     41\u001b[39m fut = asyncio.run_coroutine_threadsafe(f(*args, **kwargs), \u001b[38;5;28mself\u001b[39m.loop)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\weaviate\\collections\\queries\\near_text\\query.py:97\u001b[39m, in \u001b[36m_NearTextQueryAsync.near_text\u001b[39m\u001b[34m(self, query, certainty, distance, move_to, move_away, limit, offset, auto_limit, filters, group_by, rerank, target_vector, include_vector, return_metadata, return_properties, return_references)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnear_text\u001b[39m(\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     29\u001b[39m     query: Union[List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     return_references: Optional[ReturnReferences[TReferences]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     46\u001b[39m ) -> QuerySearchReturnType[Properties, References, TProperties, TReferences]:\n\u001b[32m     47\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search for objects in this collection by text using text-capable vectorization module and vector-based similarity search.\u001b[39;00m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[33;03m    See the [docs](https://weaviate.io/developers/weaviate/api/graphql/search-operators#neartext) for a more detailed explanation.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m            If the request to the Weaviate server fails.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     res = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._query.near_text(\n\u001b[32m     98\u001b[39m         near_text=query,\n\u001b[32m     99\u001b[39m         certainty=certainty,\n\u001b[32m    100\u001b[39m         distance=distance,\n\u001b[32m    101\u001b[39m         move_to=move_to,\n\u001b[32m    102\u001b[39m         move_away=move_away,\n\u001b[32m    103\u001b[39m         limit=limit,\n\u001b[32m    104\u001b[39m         offset=offset,\n\u001b[32m    105\u001b[39m         autocut=auto_limit,\n\u001b[32m    106\u001b[39m         filters=filters,\n\u001b[32m    107\u001b[39m         target_vector=target_vector,\n\u001b[32m    108\u001b[39m         group_by=_GroupBy.from_input(group_by),\n\u001b[32m    109\u001b[39m         rerank=rerank,\n\u001b[32m    110\u001b[39m         return_metadata=\u001b[38;5;28mself\u001b[39m._parse_return_metadata(return_metadata, include_vector),\n\u001b[32m    111\u001b[39m         return_properties=\u001b[38;5;28mself\u001b[39m._parse_return_properties(return_properties),\n\u001b[32m    112\u001b[39m         return_references=\u001b[38;5;28mself\u001b[39m._parse_return_references(return_references),\n\u001b[32m    113\u001b[39m     )\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result_to_query_or_groupby_return(\n\u001b[32m    115\u001b[39m         res,\n\u001b[32m    116\u001b[39m         _QueryOptions.from_input(\n\u001b[32m   (...)\u001b[39m\u001b[32m    126\u001b[39m         return_references,\n\u001b[32m    127\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nicet\\miniconda3\\envs\\github-hack-night\\Lib\\site-packages\\weaviate\\collections\\grpc\\query.py:490\u001b[39m, in \u001b[36m_QueryGRPC.__call\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.code().name == PERMISSION_DENIED:\n\u001b[32m    489\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InsufficientPermissionsError(e)\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateQueryError(\u001b[38;5;28mstr\u001b[39m(e), \u001b[33m\"\u001b[39m\u001b[33mGRPC search\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# pyright: ignore\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m WeaviateRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateQueryError(\u001b[38;5;28mstr\u001b[39m(e), \u001b[33m\"\u001b[39m\u001b[33mGRPC search\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mWeaviateQueryError\u001b[39m: Query call with protocol GRPC search failed with message <AioRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"explorer: get class: vectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: connection to: OpenAI API failed with status: 429 request-id: req_7aab3df7c2cb22a7a851889a26e75bdd error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"explorer: get class: vectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: connection to: OpenAI API failed with status: 429 request-id: req_7aab3df7c2cb22a7a851889a26e75bdd error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", grpc_status:2, created_time:\"2025-03-06T02:41:14.0203446+00:00\"}\"\n>."
          ]
        }
      ],
      "source": [
        "# Use the LLM chain\n",
        "user_query = input(\"What types of books are you looking for? \")\n",
        "result = llm_chain(user_query)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "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\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "load_dotenv()\n",
        "apikey = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(apikey)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" client = OpenAI(api_key=apikey)\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    store=True,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n",
        "    ]\n",
        ") \"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "github-hack-night",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
